The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.
Device 0 is not available, available devices are []
Device 1 is not available, available devices are []
Device 2 is not available, available devices are []
Traceback (most recent call last):
  File "/home/ctisseau/llm_lcd_finetune/test_cfg.py", line 175, in <module>
    finetune_test(
  File "/home/ctisseau/llm_lcd_finetune/test_cfg.py", line 45, in finetune_test
    model = AutoModelForCausalLM.from_pretrained(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ctisseau/miniconda3/envs/clm_finetune/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 571, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ctisseau/miniconda3/envs/clm_finetune/lib/python3.11/site-packages/transformers/modeling_utils.py", line 309, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ctisseau/miniconda3/envs/clm_finetune/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4555, in from_pretrained
    device_map = _get_device_map(model, device_map, max_memory, hf_quantizer, torch_dtype, keep_in_fp32_regex)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ctisseau/miniconda3/envs/clm_finetune/lib/python3.11/site-packages/transformers/modeling_utils.py", line 1315, in _get_device_map
    inferred_max_memory = get_balanced_memory(
                          ^^^^^^^^^^^^^^^^^^^^
  File "/home/ctisseau/miniconda3/envs/clm_finetune/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 978, in get_balanced_memory
    num_devices = len([d for d in max_memory if torch.device(d).type == expected_device_type and max_memory[d] > 0])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ctisseau/miniconda3/envs/clm_finetune/lib/python3.11/site-packages/accelerate/utils/modeling.py", line 978, in <listcomp>
    num_devices = len([d for d in max_memory if torch.device(d).type == expected_device_type and max_memory[d] > 0])
                                                ^^^^^^^^^^^^^^^
RuntimeError: Cannot access accelerator device when none is available.
